{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Market Analysis using Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anik Chakraborty (waytoanik@outlook.com)\n",
    "How to setup Jupyter Notebook to run Scala and Spark?\n",
    "\n",
    "https://www.techentice.com/how-to-setup-jupyter-notebook-to-run-scala-and-spark/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTION\n",
    "\n",
    "Background and Objective:\n",
    "\n",
    "Your client, a Portuguese banking institution, ran a marketing campaign to convince potential customers to invest in a bank term deposit scheme. \n",
    "The marketing campaigns were based on phone calls. Often, the same customer was contacted more than once through phone, in order to assess if they would want to subscribe to the bank term deposit or not. You have to perform the marketing analysis of the data generated by this campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://Anik:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1618673197431)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: String = 3.1.1\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: String = Anik\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.get(\"spark.driver.host\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create a Spark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bankFile: org.apache.spark.sql.Dataset[String] = [value: string]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bankFile = spark.read.textFile(\"C:/Users/wayto/Desktop/Big Data/data.csv\")\n",
    ".map(_.stripPrefix(\"\\\"\").stripSuffix(\"\\\"\"))\n",
    ".map(_.replace(\"\\\"\\\"\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|age;job;marital;e...|\n",
      "|58;management;mar...|\n",
      "|44;technician;sin...|\n",
      "|33;entrepreneur;m...|\n",
      "|47;blue-collar;ma...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bankFile.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bankDf: org.apache.spark.sql.DataFrame = [age: int, job: string ... 15 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bankDf = spark.read.option(\"inferSchema\",\"True\")\n",
    "    .option(\"header\",\"True\")\n",
    "    .option(\"delimiter\",\";\")\n",
    "    .csv(bankFile)\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bankDf.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bankDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Give marketing success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankDf.createOrReplaceTempView(\"bankView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "campSubs: Long = 5289\r\n",
       "campAll: Long = 45211\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val campSubs = spark.sql(\"SELECT count(*) as cnt FROM bankView WHERE y='yes'\").first.getAs[Long](\"cnt\")\n",
    "val campAll = spark.sql(\"SELECT count(*) as cnt FROM bankView\").first.getAs[Long](\"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "successPer: Float = 11.698481\r\n",
       "failurePer: Float = 88.30152\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val successPer = (campSubs.floatValue()/campAll.floatValue())*100\n",
    "val failurePer = 100 - (campSubs.floatValue()/campAll.floatValue())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketing success rate is: 11.698481%\n",
      "Marketing failure rate is: 88.30152%\n"
     ]
    }
   ],
   "source": [
    "println(s\"Marketing success rate is: $successPer%\")\n",
    "println(s\"Marketing failure rate is: $failurePer%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Give the maximum, mean, and minimum age of the average targeted customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+------+\n",
      "|maxAge|          meanAge|minAge|\n",
      "+------+-----------------+------+\n",
      "|    95|40.93621021432837|    18|\n",
      "+------+-----------------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ageDetails: org.apache.spark.sql.DataFrame = [maxAge: int, meanAge: double ... 1 more field]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageDetails = spark.sql(\"SELECT max(age) as maxAge, avg(age) as meanAge, min(age) as minAge FROM bankView\")\n",
    "\n",
    "ageDetails.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check the quality of customers by checking average balance, median balance of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|    averageBalance|medianBalance|\n",
      "+------------------+-------------+\n",
      "|1362.2720576850766|        448.0|\n",
      "+------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "balanceDetails: org.apache.spark.sql.DataFrame = [averageBalance: double, medianBalance: double]\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val balanceDetails = spark.sql(\"SELECT avg(balance) as averageBalance, percentile(balance, 0.5) as medianBalance FROM bankView\")\n",
    "balanceDetails.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check if age matters in marketing subscription for deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|age|  y|cnt|\n",
      "+---+---+---+\n",
      "| 18|yes|  7|\n",
      "| 18| no|  5|\n",
      "| 19|yes| 11|\n",
      "| 19| no| 24|\n",
      "| 20|yes| 15|\n",
      "| 20| no| 35|\n",
      "| 21|yes| 22|\n",
      "| 21| no| 57|\n",
      "| 22|yes| 40|\n",
      "| 22| no| 89|\n",
      "| 23|yes| 44|\n",
      "| 23| no|158|\n",
      "| 24|yes| 68|\n",
      "| 24| no|234|\n",
      "| 25|yes|113|\n",
      "| 25| no|414|\n",
      "| 26|yes|134|\n",
      "| 26| no|671|\n",
      "| 27|yes|141|\n",
      "| 27| no|768|\n",
      "+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ageGrouped: org.apache.spark.sql.DataFrame = [age: int, y: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageGrouped = spark.sql(\"SELECT age, y, count(*) as cnt FROM bankView GROUP BY age,y ORDER BY age,y DESC\")\n",
    "ageGrouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above data is not giving us much clear view, instead let's create some age groups of 18-30, 31-60, 61-95 (Min value of Age in the dataset is 18 and max value is 95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+\n",
      "|ageGps|Subscribed|counts|\n",
      "+------+----------+------+\n",
      "| 18-30|       yes|  1145|\n",
      "| 18-30|        no|  5885|\n",
      "| 31-60|       yes|  3642|\n",
      "| 31-60|        no| 33351|\n",
      "| 61-95|       yes|   502|\n",
      "| 61-95|        no|   686|\n",
      "+------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ageGp: org.apache.spark.sql.DataFrame = [ageGps: string, Subscribed: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageGp = spark.sql(\"\"\" SELECT CASE \n",
    "        WHEN Age>= 18 AND Age <= 30 THEN '18-30' \n",
    "        WHEN Age>= 31 AND Age <= 60 THEN '31-60' \n",
    "        WHEN Age>= 61 AND Age <= 95 THEN '61-95' \n",
    "        ELSE 'Other' END as ageGps, y as Subscribed, count(*) as counts FROM bankView GROUP BY ageGps, y ORDER BY ageGps, y DESC \"\"\")\n",
    "\n",
    "ageGp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that this campaign has targeted age group 31-60 the most and this age group has the highest subscribers though campaign success rate is higher for age group 18-30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check if marital status mattered for a subscription to deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+\n",
      "| marital|Subscribed|counts|\n",
      "+--------+----------+------+\n",
      "|divorced|       yes|   622|\n",
      "|divorced|        no|  4585|\n",
      "| married|       yes|  2755|\n",
      "| married|        no| 24459|\n",
      "|  single|       yes|  1912|\n",
      "|  single|        no| 10878|\n",
      "+--------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "maritalGrouped: org.apache.spark.sql.DataFrame = [marital: string, Subscribed: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val maritalGrouped = spark.sql(\"SELECT marital, y as Subscribed, count(*) as counts FROM bankView GROUP BY marital,y ORDER BY marital,y DESC\")\n",
    "maritalGrouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "divorcedY: Float = 622.0\r\n",
       "divorcedN: Float = 4585.0\r\n",
       "divorcedPer: Float = 11.945457\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for divorced\n",
    "\n",
    "val divorcedY = maritalGrouped.filter($\"marital\" === \"divorced\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val divorcedN = maritalGrouped.filter($\"marital\" === \"divorced\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val divorcedPer = (divorcedY/(divorcedY+divorcedN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marriedY: Float = 2755.0\r\n",
       "marriedN: Float = 24459.0\r\n",
       "marriedPer: Float = 10.123466\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for married\n",
    "\n",
    "val marriedY = maritalGrouped.filter($\"marital\" === \"married\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val marriedN = maritalGrouped.filter($\"marital\" === \"married\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val marriedPer = (marriedY/(marriedY+marriedN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "singleY: Float = 1912.0\r\n",
       "singleN: Float = 10878.0\r\n",
       "singlePer: Float = 14.949179\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for single\n",
    "\n",
    "val singleY = maritalGrouped.filter($\"marital\" === \"single\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val singleN = maritalGrouped.filter($\"marital\" === \"single\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val singlePer = (singleY/(singleY+singleN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign success rate for: \n",
      " Divorced is: 11.945457% \n",
      " Married is: 10.123466%  \n",
      " Single is: 14.949179% \n"
     ]
    }
   ],
   "source": [
    "println(s\"Campaign success rate for: \\n Divorced is: $divorcedPer% \\n Married is: $marriedPer%  \\n Single is: $singlePer% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations 1:\n",
    "1. This campaign targeted Married customers the most, then followed by Single and Divorced.\n",
    "2. Campaign success rate for Single customers is the highest. So more single customers should have been considered for this campaign.\n",
    "3. There is no significant different between campaign success rate among Divorced and Married customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check if age and marital status together mattered for a subscription to deposit scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+------+\n",
      "|ageGroups| marital|Subscribed|counts|\n",
      "+---------+--------+----------+------+\n",
      "|    18-30|divorced|       yes|    18|\n",
      "|    18-30|divorced|        no|   152|\n",
      "|    18-30| married|       yes|   182|\n",
      "|    18-30| married|        no|  1879|\n",
      "|    18-30|  single|       yes|   945|\n",
      "|    18-30|  single|        no|  3854|\n",
      "|    31-60|divorced|       yes|   507|\n",
      "|    31-60|divorced|        no|  4331|\n",
      "|    31-60| married|       yes|  2177|\n",
      "|    31-60| married|        no| 22021|\n",
      "|    31-60|  single|       yes|   958|\n",
      "|    31-60|  single|        no|  6999|\n",
      "|    61-95|divorced|       yes|    97|\n",
      "|    61-95|divorced|        no|   102|\n",
      "|    61-95| married|       yes|   396|\n",
      "|    61-95| married|        no|   559|\n",
      "|    61-95|  single|       yes|     9|\n",
      "|    61-95|  single|        no|    25|\n",
      "+---------+--------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ageMarital: org.apache.spark.sql.DataFrame = [ageGroups: string, marital: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageMarital = spark.sql(\"\"\" SELECT CASE \n",
    "        WHEN Age>= 18 AND Age <= 30 THEN '18-30' \n",
    "        WHEN Age>= 31 AND Age <= 60 THEN '31-60' \n",
    "        WHEN Age>= 61 AND Age <= 95 THEN '61-95' \n",
    "        ELSE 'Other' END as ageGroups, marital, y as Subscribed, count(*) as counts FROM bankView GROUP BY ageGroups, marital, y ORDER BY ageGroups, marital, y DESC \"\"\")\n",
    "\n",
    "ageMarital.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations 2:\n",
    "\n",
    "1. For age group 18-30, Single customers are the most subscribed customers as well as the campaign success rate is the highest for them.\n",
    "2. For age group 31-60, though most of the subscribed customers are Married, but success rate is a bit higher for Single customers.\n",
    "3. For age group 61-95, number of targeted customers are lesser that other groups. In this age group Married customers have subscribed the most but campaign success rate is highest for Divorced customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Do feature engineering for the bank and find the right age effect on the campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 7 Age Groups to do a detailed analysis to identify the age effect on this campaign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+\n",
      "|ageGroups|Subscribed|counts|\n",
      "+---------+----------+------+\n",
      "|    18-30|       yes|  1145|\n",
      "|    18-30|        no|  5885|\n",
      "|    31-40|       yes|  1812|\n",
      "|    31-40|        no| 15875|\n",
      "|    41-50|       yes|  1019|\n",
      "|    41-50|        no| 10220|\n",
      "|    51-60|       yes|   811|\n",
      "|    51-60|        no|  7256|\n",
      "|    61-70|       yes|   284|\n",
      "|    61-70|        no|   417|\n",
      "|    71-80|       yes|   175|\n",
      "|    71-80|        no|   213|\n",
      "|    81-95|       yes|    43|\n",
      "|    81-95|        no|    56|\n",
      "+---------+----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ageBin: org.apache.spark.sql.DataFrame = [ageGroups: string, Subscribed: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageBin = spark.sql(\"\"\" SELECT CASE \n",
    "        WHEN Age>= 18 AND Age <= 30 THEN '18-30' \n",
    "        WHEN Age>= 31 AND Age <= 40 THEN '31-40' \n",
    "        WHEN Age>= 41 AND Age <= 50 THEN '41-50' \n",
    "        WHEN Age>= 51 AND Age <= 60 THEN '51-60' \n",
    "        WHEN Age>= 61 AND Age <= 70 THEN '61-70' \n",
    "        WHEN Age>= 71 AND Age <= 80 THEN '71-80' \n",
    "        WHEN Age>= 81 AND Age <= 95 THEN '81-95' \n",
    "        ELSE 'Other' END as ageGroups, y as Subscribed, count(*) as counts FROM bankView GROUP BY ageGroups,y \n",
    "        ORDER BY ageGroups,y DESC \"\"\")\n",
    "\n",
    "ageBin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's analyze the success rate of 18-30, 31-40, 41-50, 51-60 these 4 age groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age18Y: Float = 1145.0\r\n",
       "age18N: Float = 5885.0\r\n",
       "success18Per: Float = 16.28734\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for age group 18-30\n",
    "\n",
    "val age18Y = ageBin.filter($\"ageGroups\" === \"18-30\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val age18N = ageBin.filter($\"ageGroups\" === \"18-30\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val success18Per = (age18Y/(age18Y+age18N))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age31Y: Float = 1812.0\r\n",
       "age31N: Float = 15875.0\r\n",
       "success31Per: Float = 10.244813\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for age group 31-40\n",
    "\n",
    "val age31Y = ageBin.filter($\"ageGroups\" === \"31-40\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val age31N = ageBin.filter($\"ageGroups\" === \"31-40\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val success31Per = (age31Y/(age31Y+age31N))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age41Y: Float = 1019.0\r\n",
       "age41N: Float = 10220.0\r\n",
       "success41Per: Float = 9.066643\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for age group 41-50\n",
    "\n",
    "val age41Y = ageBin.filter($\"ageGroups\" === \"41-50\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val age41N = ageBin.filter($\"ageGroups\" === \"41-50\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val success41Per = (age41Y/(age41Y+age41N))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age51Y: Float = 811.0\r\n",
       "age51N: Float = 7256.0\r\n",
       "success51Per: Float = 10.053304\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//campaign success rate for age group 51-60\n",
    "\n",
    "val age51Y = ageBin.filter($\"ageGroups\" === \"51-60\").filter($\"Subscribed\" === \"yes\").first.getAs[Long](\"counts\").floatValue()\n",
    "val age51N = ageBin.filter($\"ageGroups\" === \"51-60\").filter($\"Subscribed\" === \"no\").first.getAs[Long](\"counts\").floatValue()\n",
    "val success51Per = (age51Y/(age51Y+age51N))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign success rate for age group 18-30 is: 16.28734%\n",
      "Campaign success rate for age group 31-40 is: 10.244813%\n",
      "Campaign success rate for age group 41-50 is: 9.066643%\n",
      "Campaign success rate for age group 51-60 is: 10.053304%\n"
     ]
    }
   ],
   "source": [
    "println(s\"Campaign success rate for age group 18-30 is: $success18Per%\")\n",
    "println(s\"Campaign success rate for age group 31-40 is: $success31Per%\")\n",
    "println(s\"Campaign success rate for age group 41-50 is: $success41Per%\")\n",
    "println(s\"Campaign success rate for age group 51-60 is: $success51Per%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations 3:\n",
    "\n",
    "1. This campaign targeted age group of 31-40 the most and then followed by 41-50, 51-60, 18-30 and other age groups.\n",
    "2. Most of the subscribed customers belong to the age group of 31-40, followed by 18-30, 41-50, 51-60 age groups.\n",
    "3. This Campaign has an overall success rate 11.698481%, where the success rate for the age group 18-30 is 16.28734%. Age group 51-60 and 31-40 have almost the same success rate. It can be concluded that more focus should have been given to 18-30 age group. This campaign underestimated the age group 18-30 as a potential customer to invest in a bank term deposit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
